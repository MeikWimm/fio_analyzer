\chapter{Grundlagen}
\label{cha:Grundlagen}
Benchmarking spielt eine wichtige Rolle zum Testen von Hardware und Software.
Um die Performanz von Hardware [Q] oder auch Software [Q] zu untersuchen Tests verwendet
um Performanz wie I/O-Geschwindigkeit oder CPU-Geschwindigkeit zu messen [Q].


\section{Benchmarking}

Benchmarks sind Tests, die die Performanz von Hardware oder Software misst. Diese Messungen werden evaluiert
um verschiedene Hardware zu vergleichen [https://www.sciencedirect.com/topics/computer-science/performance-benchmark].
Das verwendete Benchmarking-Tool fio misst die Performanz der I/O-Geschwindigkeit einer Festplatte oder auch eines Dateisystems. [fio]
Probleme die bei den Messungen begrenzen sind nicht-deterministische Faktoren wie buffer caches, disk caches oder auch kernel daemons [A Nine Year Study].

\subsection{Fio-Tool}
Das Benchmarking-Tool arbeitet in der Konsole, z.B in Cygwin, und es gibt keine UI.
Um das Programm auszuführen werden zusätzlich Parameter verwendet.
Um einen Festplattenbenchmark-Test selber durchzuführen, sieht der Command wie folgt aus:

$./fio --rw=write --runtime=2s --write_bw_log=mytest --name=test --size=1024m$

\begin{center}
  \begin{table}
    \begin{tabularx}{\textwidth}{|X|X|}
      \hline
        Parameter& Defintion \\ 
      \hline
      fio & Das fio Executable  \\ 
      \hline
      rw & Auswahl von read oder write des Tests  \\ 
      \hline
      runtime & Maximale Dauer eines Tests  \\ 
      \hline
      write bw log &  Name des Logs die ausgeben werden soll   \\ 
      \hline
      name &  Name des Tests   \\ 
      \hline
      size & Größe der Datei für den read/write Test    \\ 
      \hline
    \end{tabularx}
    \caption{Beispiel Command zur Ausführung des Fio-Tools}
    \label{tab:1d_1_sta}
  \end{table}
\end{center}

Die Commands können auch als eine .fio geschrieben werden. In dieser Arbeit so eine Ausführung als einen \textit{run/job} bezeichnet.
Der Job oben testet das Random Read mit einer Laufzeit (Runtime) von 2 Sekunden und liest eine Datei mit einer Größe von 128 Mebibyte.

\subsection{Warmup und stationärer Zustand}

Bevor der stationäre Zustand erfolgt, ist ein Warmup erforderlich.
Dieser Warmup wird auch als transiente Zustand bezeichnet.

Bei Hardware oder Software ist anfangs wiederholtes testen notwendig, um
sie analysieren zu können. Erst nach diesen sogenannten Warm-ups wird der
station¨are Zustand der Performanz (engl. steady state of peak performance)
erreicht [3].

Wenn man das Lesen/Schreiben auf demselben System mit derselben Datei
testet, ist die Bandbreitengeschwindigkeit im Durchschnitt nie die gleiche. Sie
wird immer abweichen. Ursachen daf¨ur könnten schon verschiedene CPU-Temperaturen sein, 
aber auch CPU-Scaling oder parallele Prozessierung [7]. Das Fio
selbst arbeitet nicht nur mit einem Thread, sondern es arbeitet mit Multi-
threads, was nicht-deterministische Zustände hervorrufen kann. Weitere nicht-
deterministische Faktoren sind die Caches die beim Lesen oder Schreiben ver-
wendet werden, je nach dem ob sie leer sind oder schon beschrieben wurden.
Auch nicht essentielle Prozesse (oder auch essentielle Prozesse wie Daemons3),
die immer Hintergrund laufen, können die Geschwindigkeit beeinflussen [15].

Der stationärer Zustand ist ein Muster, das sich mit der Zeit wiederholt und bei dem das Verhalten in einem Zeitraum von der 
gleichen Natur ist wie in jedem anderen Zeitraum. Um zu ermitteln,
wann der stationäre Zustand eingetreten ist, sind stabile Messwerte erforderlich.
Da der Nichtdeterminismus Schwankungen in den Messungen verursacht, müssen dies in Betracht gezogen werden.
Diese Schwankung die bei den Messungen entstehen werden mit einer selbst gewählt Fehlerrate innerhalb des Analysetools ausgewählt.

\textit{Der Standardwert wird $\alpha$ = 0.05 sein.}. Die Fehlerrate dient für die Ermittlung des stationäre Zustandes.
Da sich die Geschwindigkeit nie konstant einem Wert nähert, sondern stets
abweicht, soll das Analysetool in Zukunft mit statistischen Tests mit der zusätzlichen Fehlerrate den stationären
Zustand ermitteln und dabei den Nichtdeterminismus berücksichtigen.

 Ein Beispiel, wo solche Warmups erforderlich sind, ist die JIT
(Just-In-Time) Kompilierung in Java. Der Bytecode wird während der Laufzeit
des Programms kompiliert. Damit verbessert man die Performanz von Java-
Anwendungen [8]. Ein stationärer Zustand im Festplattenbenchmarking ist er-
reicht, wenn die I/O-Geschwindigkeit wiederholte Muster aufweist, sodass die
Geschwindigkeiten zu verschiedenen Zeitpunkten nach diesem Zustand gleich
sind.2 Vor dem stationären Zustand erfolgt der Warm-Up, wo die Caches des
Rechners befüllt werden [15]. Dieser Zeitraum wird auch als transienten Zustand
bezeichnet [11]. Auch wenn der Warm-up erfolgt ist, ist der Nichtdeterminismus
dabei ein Hindernis.

Die Abweichungen können im niedrigen Prozentbereich liegen. Es wird jedoch nicht
ausreichen, ein paar Tests durchzuführen und anschließend die Logs auszuwerten. 
Denn nach dem Warm-up wird ein größeres Problem darin bestehen,
welche Logs die Informationen beinhalten, wo auch der Warm-Up stattfand und
der transiente Zustand abgeschlossen wurde. Die Auswahl der Logs und deren
Auswertung können signifikante Unterschiede aufweisen, die die Evaluierung
verändern würden [1].



\section{Statistische Analyse/Tests}
Um zu entscheiden, ob eine Performanzänderung vorliegt, müssen durch die Messung
ermittelte Stichproben von Zufallsvariablen verglichen werden. Hierfür werden verschie-
dene statistische Tests eingesetzt [GBE07]. 
Die Grundgesamtheit werden alle Logs sein und daraus werden paarweise die Stichproben entnommen die für die Tests verwendet.
Diese statistische Tests wird ausgesagt, ob eine statistische Signifikanz zwischen den Stichproben vorhanden ist.
Wenn die statistisch Signifikanz erfüllt ist, wird die Nullhypothese abgelehnt.
Die Nullhypothese ist hier, zwischen den Logs keine Abhängigkeit besteht.
Somit ist die Alternativhypothese, dass zwischen den ausgewählten Stichproben ein Zusammenhang besteht.
Um die Nullhypothese zu überprüfen wird ein p-wert (Signifikanz Wahrscheinlichkeit) berechnet und mit einem selbst
festgelegtem Signifikanzniveau $\alpha$ verglichen.
Dieser p-Wert sagt aus wie die Wahrscheinlichkeit ist eine Nullhypothese falsch anzunehmen. 
Ein p-Wert von 0.5 sagt aus, dass es eine 5\%-ige Wahrscheinlichkeit gibt das die Nullhypothese inkorrekt abgelehnt wurde, obwohl sie erfüllt ist.
Somit ist die Wahrscheinlichkeit für die Alternativhypothese (1 - p) also 95\% \cite{statistics}.
Wenn $\alpha > p$ mit $\alpha = 0.05$ ist eine statistische Signifikanz vorhanden ist, wird die Nullhypothese abgelehnt. 
Ein weiterer Messwert in den Tests ist der z-Wert. Dieser Wert gibt an viele Standardabweichungen ein ROHwert unter
bzw. über dem Mittelwert liegt.

Im Folgenden werden statistische Tests im
Allgemeinen, der T-Test, der Konfidenzintervallvergleich und weitere statistische Tests
vorgestellt.

\section{Varianzanalyse - Analysis of Variance (ANOVA)}

Dieses Kapitel führt eine allgemeine statistische Analysetechnik ein, die als Varianzanalyse (ANOVA) bezeichnet wird. 
ANOVA unterteilt die gesamte beobachtete Variation in einer Reihe von Messungen in mehrere Komponenten.
Diese Komponenten werden SSA und SSE sein.
Die SSA (Sum of Squared errors of All treatment) ist die quadratische Abweichung der Mittelwerte vom Gesamtmittelwert und die SSE 
(Sum of Squared Errors of all observation) ist die gesamte Abweichung von den Mittelwerten in den Gruppen.
Das Ziel der Komponenten ist, festzustellen, ob die beobachteten Unterschiede zwischen den Mittelwerten der einzelnen Alternativen auf tatsächliche 
Unterschiede zwischen den Alternativen zurückzuführen sind oder ob sie lediglich Messfehler sind.
Die Alternativen hier werden die Iterationen eines fio-runs sein.
Die Varianzanalyse geht davon aus, dass die Fehler in den Messungen für die verschiedenen Alternativen
unabhängig voneinander und normalverteilt sind.
Es geht weiter davon aus, dass die Varianz der Messfehler bei allen Alternativen gleicher Art sind.
Die Tabelle \ref{tab:measurements} zeigt die Vorbereitung einer Varianzanalyse für einen fio-run.

\begin{table}[h!]
  \centering
  %\resizebox{\textwidth}{!}{
  \begin{tabular}{|c|*{5}{c}|c|}
  \hline
  \textbf{Messwerte} & \multicolumn{5}{c|}{\textbf{Iterationen/Alternativen}} & \textbf{Gesamtmittelwert} \\
  \cline{2-6}
   & 1 & 2 & $\cdots$ & $k-1$ & $k$ & \\
  \hline
  1 & $y_{11}$ & $y_{12}$ & $\cdots$ & $y_{1j}$ & $y_{1k}$ & \\
  2 & $y_{21}$ & $y_{22}$ & $\cdots$ & $y_{2j}$ & $y_{2k}$ & \\
  $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ & \\
  $i$ & $y_{i1}$ & $y_{i2}$ & $\cdots$ & $y_{ij}$ & $y_{ik}$ & \\
  $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ & \\
  $n$ & $y_{n1}$ & $y_{n2}$ & $\cdots$ & $y_{nj}$ & $y_{nk}$ &  \\
  \hline
  Spaltenmittelwert & $\bar{y}_{\cdot1}$ & $\bar{y}_{\cdot2}$ & $\cdots$ & $\bar{y}_{\cdot j}$ & $\bar{y}_{\cdot k}$ & $\bar{y}_{\cdot \cdot}$ \\
  %Effekte & $\alpha_{\cdot 1}$ & $\alpha_{\cdot 2}$ & $\cdots$ & $\alpha_{\cdot k-1}$ & $\cdots$ & $\alpha_{\cdot k}$ \\
  \hline
  \end{tabular}
  %}
  \caption{Tabelle mit einem fio-Run mit k-Iterationen und n-Messwerte für die Varianzanalyse}
  \label{tab:measurements}
\end{table}

Die Messwerte werden die I/O-Geschwindigkeiten sein. Genauer ist die ANOVA, die hier verwendet wird, eine einfaktor ANOVA.
Der Faktor ist hier die I/O-Geschwindigkeit. Wenn mehr als ein Faktor verwendet wird, wird die ANOVA auch als mehrfaktor ANOVA bezeichnet.
Da aber nur ein fio-run mit mehren Iteration verglichen werden soll, wird die einfaktor ANOVA verwendet.
Für die Analyse werden folgende Formel verwendet:

\begin{center}
  \begin{table}[h!]
    \begin{tabularx}{\textwidth}{|X|X|}
      \hline
        Formel & Definition \\ 
      \hline
      $\overline{y}_{\cdot j} = \dfrac{\sum_{i=1}^{n} y_{ij}}{n}$ & Das fio Executable  \\ 
      rw & Auswahl von read oder write des Tests  \\ 
      \hline
      runtime & Maximale Dauer eines Tests  \\ 
      \hline
      write bw log &  Name des Logs die ausgeben werden soll   \\ 
      \hline
      name &  Name des Tests   \\ 
      \hline
      size & Größe der Datei für den read/write Test    \\ 
      \hline
    \end{tabularx}
    \caption{Beispiel Command zur Ausführung des Fio-Tools}
    \label{tab:formel_mittelwerte}
  \end{table}
\end{center}

Aus den beiden Komponenten SSA und SSE ergibt sich SST.
Sie ist die Summe der Quadrate der Differenzen zwischen jeder Messung und dem Gesamtmittelwert.
Mit der Berechnung des Verhältnisses von SSA und SST, wird ausgesagt, wie viel Unterschied zwischen den Alternativen war.
und mit dem Verhältnis von SSE unt SST, wie viel Variation durch Messfehler entstanden sind.  

\subsection{F-Test}
Um die statistische Signifikanz zu testen wird für ANOVA der F-Test genutzt.
Dieser auf der F-Verteilung basierende Test wird verwendet, um zu prüfen, ob sich zwei Varianzen signifikant unterscheiden.
Der lässt mit den Verhältnissen von SSA und SSE berechnen.
Da es sich bei dieser F-Statistik um das Verhältnis zweier Varianzen handelt, sind tatsächlich zwei Werte für die Freiheitsgrade erforderlich, 
einer aus dem Zähler und einer aus dem Nenner.
Wenn dieses Verhältnis, der berechnete F-Wert, größer ist als der kritische F-Wert, der bei einem bestimmten Signifikanzniveau $\alpha$ aus der F-Verteilung erhalten wird, 
schließen wir, dass der Unterschied in den Varianzen statistisch signifikant ist. Daraus ergibt sich, 
dass es einen statistisch signifikanten Unterschied zwischen den Alternativen gibt, der über die Unterschiede aufgrund experimenteller Fehler hinausgeht.

\begin{center}
  \begin{table}[h!]
    \begin{tabularx}{\textwidth}{|X|X|X|}
      \hline
       $s_a = SSA ( k -1)$ & $s_a = SSA ( k -1)$ & $F = s/s$\\ 
      \hline
    \end{tabularx}
    \caption{Berechnung des F-Wertes mit mean-square SSA und SSE}
    \label{tab:f_computing}
  \end{table}
\end{center}

\section{Konfidenzintervalle}
Es wird angenommen das die Grundgesamtheit normalverteilt sind [QUELLE].
Die Stichprobenverteilung wird in eine Standnormalverteilung überführt, mit:

\begin{center}
  $z = \dfrac{\overline{x} - \mu}{\sigma_{\overline{x}}}$
\end{center}

Die Standardabweichung sagt nicht aus ob der Wert kein "ausreißer" ist. Dafür wird die Konfidenzintervalle verwendet
um akkurater zu sein.
Die Wahrscheinlichkeit dafür, dass der z-Wert
größer ist als das $z_{\alpha/2}$ und kleiner
als das $z_{1-\alpha/2}$ Perzentil ist, beträgt $1 - \alpha$:

\begin{center}
  $P(z_{\alpha/2} \leq z \leq z_{1-\alpha/2}) = 1 - \alpha$
\end{center}

Mit hilfe der obigen Formel lässt sich diese Formel wie folgt umformen:

\begin{center}
  $P(\overline{x} - z_{1-\alpha/2} * \sigma_{\overline{x}} \leq \mu \leq \overline{x} + z_{1-\alpha/2} * \sigma_{\overline{x}}) = 1 - \alpha$
\end{center}

Diese Wahrscheinlichkeitsformel gibt an, wie der $\mu$-Wert sich in einem Konfidenzintervall mit $(1 - \alpha)$ befindet.
Der Bereich lässt sich wie folgt berechnen:

\begin{center}
  Konfidenzintervall $= [\overline{x} - z_{1-\alpha / 2} \cdot \sigma_{\overline{x}}, \overline{x} + z_{1-\alpha / 2} \cdot \sigma_{\overline{x}}]$
\end{center}

\subsection{T-Test}
Mit dem T-Test werden jeweils zwei unabhängige Stichprobe miteinander verglichen, 
unter der Annahme das die Grundgesamtheit normalverteilt ist.

\begin{center}
  $t = \dfrac{\mu_1-\mu_2}{\sqrt{\frac{s_p^2}{n_1} + \frac{s_p^2}{n_2}}}$
\end{center}

\begin{center}
  $s^2_p = \dfrac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 - 2}$
\end{center}

\begin{center}
  $|t| > t(1 - \dfrac{1}{2}\alpha, n + m - 2)$
\end{center}

Der Begriff T-Test wird genutzt, um verschiedene Tests zu bezeichnen, die
u. a. die Verteilung der Grundgesamtheit von normalverteilten und unabhängigen Stich-
proben miteinander vergleichen [JP15, Seite 41]. Im Kontext dieser Arbeit bezeichnet
der T-Test den unabhängigen T-Test, bei dem die Erwartungswerte zweier voneinander
unabhängiger Stichproben miteinander verglichen werden.
Der T-Test vergleicht die Stärke der Unterschiede zwischen den Stichproben mit der
Abweichung innerhalb der Stichproben. Die Prüfgröße t, die ein Maß dafür ist, wie un-
wahrscheinlich die Nullhypothese H0 ist, d. h. dass die Grundgesamtheiten der beiden
Stichproben den gleichen Erwartungswert aufweisen. Diese wird folgendermaßen berech-
net:
\subsection{Tukey-HSD}
Der Tukey-HSD-Test verwendet die Differenz zwischen zwei Mit-
telwerten, um ihre statistische Signifikanz zu ermitteln.
Der HSD-Wert wird mittels mittlere quadratische Abweichung (MSE) berech-
net und mit der Anzahl der Gruppen die getestet wurden. Die minimale Dif-
ferenz wird als HSD bezeichnet. Wenn aber die Differenz der Mittelwerte aus
den Tests gr¨oßer als der HSD-Wert ist, sind diese Werte statistisch signifikant.
Zus¨atzlich versucht der Tukey-HSD-Test5 die Fehlerrate von Falsch-Positiven-
Annahmen zu korrigieren. Dieser Test setzt aber voraus, dass die Stichproben
normalverteilt sind. Die t-Tests arbeiten ¨ahnlich wie die Tukey HSD Tests. Der
Unterschied besteht darin, dass sie die Fehlerrate nicht anpassen [12]. 

\subsection{Mann-Whitney-
Test}
Der Mann-Whitney-Wilcoxon-Rangsummentest [BBH+16; CGT+14; JHHF09]
[Fie13, Seiten 541ff] kann ebenfalls eingesetzt werden, um zu entscheiden, ob sich zwei
Stichproben sich signifikant unterscheiden in dem die Werte einen Rang gesetzt wird. 
Alle Werte aus den Stichproben bekommen einen Rang aufsteigend vom Kleinsten zum Größten Wert.
Die gesamte Rangsumme lässt mit der Formel berechnen:
\begin{center}
  $T_1 + T_2 = \dfrac{n * (n + 1)}{2}, (n = n_1 + n_2)$
\end{center}  

Dabei sind $T_1$ und $T_2$ die Rangsummen aus den jeweiligen Stichproben.
Für den Test folgt ein Prüfgröße $U$  
Dieser Test
hat keine Anforderungen über die Verteilung der Stichproben.
Somit ist keine Normalverteilung der Stichproben notwendig.


\section{Konzept Analysetool}
Das Analysetool wird mit den Logs des Fio-Tools analysieren.
Das Fio-Too durchläuft 5 - 10 mal die gleichen Tests, wo dann der stationäre Zustand, des Analysetools,
bestimmt werden soll. Das Tool wird in der Lage mit den drei Tests die eingeführt zu arbeiten.
Da die Anzahl nicht festgelegt werden kann, da die dieser Zustand an einem unbestimmten Zeitpunkt und Iteration erreicht wird,
werden verschiedene Anläufe getestet mit einer verschieden Anzahl and Fio-Tool Testanzahl.

\section{Notes}

- Analysetool mit logs aus einem HPC
- Steady State und Warm Up

----------------------------------------------------------------------

T-Test Beispiel:

Insgesamt Logs: 25

Aufgeilt in 	| Durschnitt I/O | Standardabweichung | Konfidenzintervall
Gruppe A | 13	| 43435.3	 | 3435

Gruppe B | 12	| 35254.6	 | 5456	

----------------------------------------------------------------------

Konfidenzintervall:

Beispiel es gibt insgesamt 55 logs (Das ist die Grundgesamtheit):
Stichprobe genommen sind 34

Verteilung -> normal Verteilt

Doch,

Beispiel es gibt insgesamt 55 logs (Das ist die Grundgesamtheit):
Stichprobe genommen sind 22

Verteilung -> Studentisch t Verteilt

Daraus wird der Mittelwert berechnet.

Varianz und Standardabweichung wird hier benötigt

Paper: oopsla07-georges.pdf

fsbench-tr.pdf Seite 8:

The standard deviation is a measure of how much variation there is between the
runs. The half-width of the confidence interval describes how far the true value may be
from the captured mean with a given degree of confidence (e.g., 95%). This provides a
better sense of the true mean. In addition, as more benchmark runs are performed, the
standard deviation may not decrease, but the width of the confidence interval will.
For experiments with less than 30 runs, one should be careful not to use the normal
distribution for calculating confidence intervals. This is because the central limit theorem
no longer holds with a small sample size. Instead, one must use the Student’s t-distribution.
This distribution may also be used for experiments with at least 30 runs, since in this case
it is similar to the normal distribution.

Vorstellung Programm:

- Signifikanzniveau selbst entscheidbar 0.01 bis 0.05 \\
- Wenn ein Zusammenhang zwischen den Stichproben nicht der Fall ist, sollte der p Wert aus den Proben kleiner als der HSD-Wert sein.\\
- So sollte der p Wert innerhalb des Signifikanzniveau sein und der stationäre Zustand sollte erreicht sein\\
- Die Werte sollen nicht signifikant Unterscheidbar sein, dann wäre der stationäre Zustand erreicht\\
- Wie soll ich die Logs mit den Tests abarbeiten ?\\
- Welche Logs sollen genommen werden ? 
