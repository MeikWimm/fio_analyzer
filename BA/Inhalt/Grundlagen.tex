\chapter{Grundlagen}
\label{cha:Grundlagen}
Benchmarking spielt eine wichtige Rolle zum Testen von Hardware und Software.
Um die Performanz von Hardware [Q] oder auch Software [Q] zu untersuchen Tests verwendet
um Performanz wie I/O-Geschwindigkeit oder CPU-Geschwindigkeit zu messen [Q].


\section{Benchmarking}

Benchmarks sind Tests, die die Performanz von Hardware oder Software misst. Diese Messungen werden evaluiert
um verschiedene Hardware zu vergleichen [https://www.sciencedirect.com/topics/computer-science/performance-benchmark].
Das verwendete Benchmarking-Tool fio misst die Performanz der I/O-Geschwindigkeit einer Festplatte oder auch eines Dateisystems. [fio]
Probleme die bei den Messungen begrenzen sind nicht-deterministische Faktoren wie buffer caches, disk caches oder auch kernel daemons [A Nine Year Study].

\subsection{Fio-Tool}
Das Benchmarking-Tool arbeitet in der Konsole, z.B in Cygwin, und es gibt keine UI.
Um das Programm auszuführen werden zusätzlich Parameter verwendet.
Um einen Festplattenbenchmark-Test selber durchzuführen, sieht der Command wie folgt aus:

$./fio --rw=write --runtime=2s --write_bw_log=mytest --name=test --size=1024m$

\begin{center}
  \begin{table}
    \begin{tabularx}{\textwidth}{|X|X|}
      \hline
        Parameter& Defintion \\ 
      \hline
      fio & Das fio Executable  \\ 
      \hline
      rw & Auswahl von read oder write des Tests  \\ 
      \hline
      runtime & Maximale Dauer eines Tests  \\ 
      \hline
      write bw log &  Name des Logs die ausgeben werden soll   \\ 
      \hline
      name &  Name des Tests   \\ 
      \hline
      size & Größe der Datei für den read/write Test    \\ 
      \hline
    \end{tabularx}
    \caption{Beispiel Command zur Ausführung des Fio-Tools}
    \label{tab:1d_1_sta}
  \end{table}
\end{center}

Die Commands können auch als eine .fio geschrieben werden. In dieser Arbeit so eine Ausführung als einen \textit{run/job} bezeichnet.
Der Job oben testet das Random Read mit einer Laufzeit (Runtime) von 2 Sekunden und liest eine Datei mit einer Größe von 128 Mebibyte.

\subsection{Warmup und stationärer Zustand}

Bevor der stationäre Zustand erfolgt, ist ein Warmup erforderlich.
Dieser Warmup wird auch als transiente Zustand bezeichnet.

Bei Hardware oder Software ist anfangs wiederholtes testen notwendig, um
sie analysieren zu können. Erst nach diesen sogenannten Warm-ups wird der
station¨are Zustand der Performanz (engl. steady state of peak performance)
erreicht [3].

Wenn man das Lesen/Schreiben auf demselben System mit derselben Datei
testet, ist die Bandbreitengeschwindigkeit im Durchschnitt nie die gleiche. Sie
wird immer abweichen. Ursachen daf¨ur könnten schon verschiedene CPU-Temperaturen sein, 
aber auch CPU-Scaling oder parallele Prozessierung [7]. Das Fio
selbst arbeitet nicht nur mit einem Thread, sondern es arbeitet mit Multi-
threads, was nicht-deterministische Zustände hervorrufen kann. Weitere nicht-
deterministische Faktoren sind die Caches die beim Lesen oder Schreiben ver-
wendet werden, je nach dem ob sie leer sind oder schon beschrieben wurden.
Auch nicht essentielle Prozesse (oder auch essentielle Prozesse wie Daemons3),
die immer Hintergrund laufen, können die Geschwindigkeit beeinflussen [15].

Der stationärer Zustand ist ein Muster, das sich mit der Zeit wiederholt und bei dem das Verhalten in einem Zeitraum von der 
gleichen Natur ist wie in jedem anderen Zeitraum. Um zu ermitteln,
wann der stationäre Zustand eingetreten ist, sind stabile Messwerte erforderlich.
Da der Nichtdeterminismus Schwankungen in den Messungen verursacht, müssen dies in Betracht gezogen werden.
Diese Schwankung die bei den Messungen entstehen werden mit einer selbst gewählt Fehlerrate innerhalb des Analysetools ausgewählt.

\textit{Der Standardwert wird $\alpha$ = 0.05 sein.}. Die Fehlerrate dient für die Ermittlung des stationäre Zustandes.
Da sich die Geschwindigkeit nie konstant einem Wert nähert, sondern stets
abweicht, soll das Analysetool in Zukunft mit statistischen Tests mit der zusätzlichen Fehlerrate den stationären
Zustand ermitteln und dabei den Nichtdeterminismus berücksichtigen.

 Ein Beispiel, wo solche Warmups erforderlich sind, ist die JIT
(Just-In-Time) Kompilierung in Java. Der Bytecode wird während der Laufzeit
des Programms kompiliert. Damit verbessert man die Performanz von Java-
Anwendungen [8]. Ein stationärer Zustand im Festplattenbenchmarking ist er-
reicht, wenn die I/O-Geschwindigkeit wiederholte Muster aufweist, sodass die
Geschwindigkeiten zu verschiedenen Zeitpunkten nach diesem Zustand gleich
sind.2 Vor dem stationären Zustand erfolgt der Warm-Up, wo die Caches des
Rechners befüllt werden [15]. Dieser Zeitraum wird auch als transienten Zustand
bezeichnet [11]. Auch wenn der Warm-up erfolgt ist, ist der Nichtdeterminismus
dabei ein Hindernis.

Die Abweichungen können im niedrigen Prozentbereich liegen. Es wird jedoch nicht
ausreichen, ein paar Tests durchzuführen und anschließend die Logs auszuwerten. 
Denn nach dem Warm-up wird ein größeres Problem darin bestehen,
welche Logs die Informationen beinhalten, wo auch der Warm-Up stattfand und
der transiente Zustand abgeschlossen wurde. Die Auswahl der Logs und deren
Auswertung können signifikante Unterschiede aufweisen, die die Evaluierung
verändern würden [1].



\section{Statistische Analyse/Tests}
Um zu entscheiden, ob eine Performanzänderung vorliegt, müssen durch die Messung
ermittelte Stichproben von Zufallsvariablen verglichen werden. Hierfür werden verschie-
dene statistische Tests eingesetzt [GBE07]. 
Die Grundgesamtheit wird ein fio-Run sein und die Stichproben werden die Iteration sein die für die tESTS entnommen werden.
Diese statistische Tests werden genutzt, um zu ermitteln ob eine statistische Signifikanz zwischen den Stichproben vorhanden ist.
Wenn die statistisch Signifikanz erfüllt ist, wird die Nullhypothese abgelehnt.
Die Nullhypothese ist hier die Annahme, dass es zwischen den Logs keine Abhängigkeit besteht und zufällig sind.
Somit ist die Alternativhypothese, dass zwischen den ausgewählten Stichproben ein Zusammenhang/Abhängigkeit besteht.
Um die Nullhypothese zu überprüfen wird ein p-wert (Signifikanz Wahrscheinlichkeit) berechnet und mit einem selbst
festgelegtem Signifikanzniveau $\alpha$ verglichen.
Dieser p-Wert sagt aus wie die Wahrscheinlichkeit ist eine Nullhypothese falsch anzunehmen. 
Ein p-Wert von 0.05 sagt aus, dass es eine 5\%-ige Wahrscheinlichkeit gibt das die Nullhypothese inkorrekt abgelehnt wurde, obwohl sie erfüllt ist.
Somit ist die Wahrscheinlichkeit für die Alternativhypothese (1 - p) also 95\% \cite{statistics}.
Wenn $\alpha > p$ mit $\alpha = 0.05$ ist eine statistische Signifikanz vorhanden ist, wird die Nullhypothese abgelehnt. 


Im Folgenden werden statistische Tests im
Allgemeinen, der T-Test, der Konfidenzintervall und weitere statistische Tests
vorgestellt.

\section{Varianzanalyse - Analysis of Variance (ANOVA)}

Dieses Kapitel führt eine allgemeine statistische Analysetechnik ein, die als Varianzanalyse (ANOVA) bezeichnet wird. 
ANOVA unterteilt die gesamte beobachtete Variation in einer Reihe von Messungen in mehrere Komponenten.
Diese Komponenten werden SSA\footnote{SSA - Sum of Squared errors of All treatment} (auch SSB \footnote{SSB}) und SSE\footnote{SSE - Sum of Squared Errors of all observation}
 (auch SSW\footnote{SSW}) sein.
Die SSA  ist die quadratische Abweichung der Mittelwerte vom Gesamtmittelwert und die SSE
ist die gesamte Abweichung von den Mittelwerten in den Gruppen.
Das Ziel der Komponenten ist, festzustellen, ob die beobachteten Unterschiede zwischen den Mittelwerten der einzelnen Alternativen auf tatsächliche 
Unterschiede zwischen den Alternativen zurückzuführen sind oder ob sie lediglich Messfehler sind.
Die Alternativen hier werden die Iterationen eines fio-runs sein.
Die Varianzanalyse geht davon aus, dass die Fehler in den Messungen für die verschiedenen Alternativen
unabhängig voneinander und normalverteilt sind.
Es geht weiter davon aus, dass die Varianz der Messfehler bei allen Alternativen gleicher Art sind.
Die Tabelle \ref{tab:measurements} zeigt die Vorbereitung einer Varianzanalyse für einen fio-run.

\begin{table}[h!]
  \centering
  %\resizebox{\textwidth}{!}{
  \begin{tabular}{|c|*{5}{c}|c|}
  \hline
  \textbf{Messwerte} & \multicolumn{5}{c|}{\textbf{Iterationen/Alternativen}} & \textbf{Gesamtmittelwert} \\
  \cline{2-6}
   & 1 & 2 & $\cdots$ & $k-1$ & $k$ & \\
  \hline
  1 & $y_{11}$ & $y_{12}$ & $\cdots$ & $y_{1j}$ & $y_{1k}$ & \\
  2 & $y_{21}$ & $y_{22}$ & $\cdots$ & $y_{2j}$ & $y_{2k}$ & \\
  $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ & \\
  $i$ & $y_{i1}$ & $y_{i2}$ & $\cdots$ & $y_{ij}$ & $y_{ik}$ & \\
  $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ & \\
  $n$ & $y_{n1}$ & $y_{n2}$ & $\cdots$ & $y_{nj}$ & $y_{nk}$ &  \\
  \hline
  Spaltenmittelwert & $\bar{y}_{\cdot1}$ & $\bar{y}_{\cdot2}$ & $\cdots$ & $\bar{y}_{\cdot j}$ & $\bar{y}_{\cdot k}$ & $\bar{y}_{\cdot \cdot}$ \\
  %Effekte & $\alpha_{\cdot 1}$ & $\alpha_{\cdot 2}$ & $\cdots$ & $\alpha_{\cdot k-1}$ & $\cdots$ & $\alpha_{\cdot k}$ \\
  \hline
  \end{tabular}
  %}
  \caption{Tabelle mit einem fio-Run mit k-Iterationen und n-Messwerte für die Varianzanalyse}
  \label{tab:measurements}
\end{table}

Die Messwerte werden die I/O-Geschwindigkeiten sein. Genauer ist die ANOVA, die hier verwendet wird, eine einfaktor ANOVA.
Der Faktor ist hier die I/O-Geschwindigkeit. Wenn mehr als ein Faktor verwendet wird, wird die ANOVA auch als mehrfaktor ANOVA bezeichnet.
Da aber nur ein fio-run mit mehren Iteration verglichen werden soll, wird die einfaktor ANOVA genutzt.
Für die ANOVA werden folgende Formel verwendet:

\begin{center}
  \begin{table}[h!]
    \begin{tabularx}{\textwidth}{|X|X|}
      \hline
        Formel & Definition \\ 
      \hline
      $\overline{y}_{\cdot j} = \dfrac{\sum_{i=1}^{n} y_{ij}}{n}$ & Das fio Executable  \\ 
      rw & Auswahl von read oder write des Tests  \\ 
      \hline
      runtime & Maximale Dauer eines Tests  \\ 
      \hline
      write bw log &  Name des Logs die ausgeben werden soll   \\ 
      \hline
      name &  Name des Tests   \\ 
      \hline
      size & Größe der Datei für den read/write Test    \\ 
      \hline
    \end{tabularx}
    \caption{Beispiel Command zur Ausführung des Fio-Tools}
    \label{tab:formel_mittelwerte}
  \end{table}
\end{center}

Aus den beiden Komponenten SSA und SSE ergibt sich SST.
Sie ist die Summe der Quadrate der Differenzen zwischen jeder Messung und dem Gesamtmittelwert.
Mit der Berechnung des Verhältnisses von SSA und SST, wird ausgesagt, wie viel Unterschied zwischen den Alternativen war.
und mit dem Verhältnis von SSE unt SST, wie viel Variation durch Messfehler entstanden sind.  
Hier ein Beispiel für die Berechnung der Verhältnissen:

\begin{center}
  $\dfrac{SSA}{SST} = \dfrac{0.7585}{0.8270} = 0.917$
\end{center}

\begin{center}
  $\dfrac{SSE}{SST} = \dfrac{0.0685}{0.8270} = 0.083$
\end{center}

Das bedeutet 91\% der gesamte Variationen in den Messwerten entstammen durch den Unterschied der Performanz und
8\% entstammten aus Ungenauigkeiten der Messwerte. 



\subsection{F-Test}
Um die statistische Signifikanz in ANOVA testen wird der F-Test genutzt.
Dieser auf der F-Verteilung basierende Test wird verwendet, um zu prüfen, ob sich zwei Varianzen signifikant unterscheiden.
Der Test lässt sich mit den Verhältnissen von SSA und SSE berechnen.
Da es sich bei dieser F-Statistik um das Verhältnis zweier Varianzen handelt, sind zwei Werte für die Freiheitsgrade erforderlich, 
einer aus dem Zähler und einer aus dem Nenner.
Wenn dieses Verhältnis, der berechnete F-Wert, größer ist als der kritische F-Wert, der bei einem bestimmten Signifikanzniveau $\alpha$ aus der F-Verteilung erhalten wird, 
schließen wir, dass der Unterschied in den Varianzen statistisch signifikant ist. Daraus ergibt sich, 
dass es einen statistisch signifikanten Unterschied zwischen den Alternativen gibt, der über die Unterschiede aufgrund experimenteller Fehler hinausgeht.

\begin{center}
  \begin{table}[h!]
    \begin{tabularx}{\textwidth}{|X|X|X|}
      \hline
       $s_a = SSA ( k -1)$ & $s_a = SSE ( k -1)$ & $F = s/s$\\ 
      \hline
    \end{tabularx}
    \caption{Berechnung des F-Wertes mit mean-square SSA und SSE}
    \label{tab:f_computing}
  \end{table}
\end{center}


\section{Tukey-HSD}
Der Tukey-HSD (Honestly Significant Difference) Test analysiert paarweise
zwischen den Mittelwerten. 
Der Test ist eine post-hoc Test was zusätzlich nach der ANOVA verwendet wird.

Zur Messung oder Analyse wurde der HSD für jedes
Mittelwertpaar mithilfe der folgenden Formel berechnet:

\begin{center}
  $HSD = \dfrac{M_i - M_j}{\sqrt{MS_w / n}}$
\end{center}

$M_i - M_j$ ist die Differenz des Mittelwertes zweier Stichproben $i$ und $j$.
Dabei gilt das der Mittelwert $M_i$ größer ist als $M_j$.
Für $MS_w$ gilt $MS_w = s^2_{e}$ ist der quadratische Mittelwert innerhalb und n ist die Anzahl
der Alternativen oder hier der Iterationen.
Um diesen Test durchzuführen werden folgende Schritte angewendet:

\begin{center}
  \begin{enumerate}
    \item Führe ANOVA durch. Wenn der F wert signifikant ist führe den post-hoc Test durchzuführen
    \item Wähle Iteration aus mit ihren Mittelwerten
    \item Verwende die oben erwähnte HSD-Formel
    \item Wähle den Tukey HSD kritischen Wert aus der Tabelle
    \item Wenn der berechnen Werte größer ist als der kritische Wert, ist das Ergebnis signifikant unterschiedlich 
  \end{enumerate}
\end{center}



\section{Konfidenzintervalle}
Es wird angenommen das die Grundgesamtheit normalverteilt sind [QUELLE].
Die Stichprobenverteilung wird in eine Standnormalverteilung überführt, mit:

\begin{center}
  $z = \dfrac{\overline{x} - \mu}{\sigma_{\overline{x}}}$
\end{center}

Die Standardabweichung sagt nicht aus ob der Wert kein "ausreißer" ist. Dafür wird die Konfidenzintervalle verwendet
um akkurater zu sein.
Die Wahrscheinlichkeit dafür, dass der z-Wert
größer ist als das $z_{\alpha/2}$ und kleiner
als das $z_{1-\alpha/2}$ Perzentil ist, beträgt $1 - \alpha$:

\begin{center}
  $P(z_{\alpha/2} \leq z \leq z_{1-\alpha/2}) = 1 - \alpha$
\end{center}

Mit hilfe der obigen Formel lässt sich diese Formel wie folgt umformen:

\begin{center}
  $P(\overline{x} - z_{1-\alpha/2} * \sigma_{\overline{x}} \leq \mu \leq \overline{x} + z_{1-\alpha/2} * \sigma_{\overline{x}}) = 1 - \alpha$
\end{center}

Diese Wahrscheinlichkeitsformel gibt an, wie der $\mu$-Wert sich in einem Konfidenzintervall mit $(1 - \alpha)$ befindet.
Der Bereich lässt sich wie folgt berechnen:

\begin{center}
  Konfidenzintervall $= [\overline{x} - z_{1-\alpha / 2} \cdot \sigma_{\overline{x}}, \overline{x} + z_{1-\alpha / 2} \cdot \sigma_{\overline{x}}]$
\end{center}

\section{T-Test}
Mit dem T-Test werden jeweils zwei unabhängige Stichprobe miteinander verglichen, 
unter der Annahme das die Grundgesamtheit normalverteilt ist.

\begin{center}
  $t = \dfrac{\mu_1-\mu_2}{\sqrt{\frac{s_p^2}{n_1} + \frac{s_p^2}{n_2}}}$
\end{center}

\begin{center}
  $s^2_p = \dfrac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2}{n_1 + n_2 - 2}$
\end{center}

\begin{center}
  $|t| > t(1 - \dfrac{1}{2}\alpha, n + m - 2)$
\end{center}

Der Begriff T-Test wird genutzt, um verschiedene Tests zu bezeichnen, die
u. a. die Verteilung der Grundgesamtheit von normalverteilten und unabhängigen Stich-
proben miteinander vergleichen [JP15, Seite 41]. Im Kontext dieser Arbeit bezeichnet
der T-Test den unabhängigen T-Test, bei dem die Erwartungswerte zweier voneinander
unabhängiger Stichproben miteinander verglichen werden.
Der T-Test vergleicht die Stärke der Unterschiede zwischen den Stichproben mit der
Abweichung innerhalb der Stichproben. Die Prüfgröße t, die ein Maß dafür ist, wie un-
wahrscheinlich die Nullhypothese H0 ist, d. h. dass die Grundgesamtheiten der beiden
Stichproben den gleichen Erwartungswert aufweisen. Diese wird folgendermaßen berech-
net:

\section{Mann-Whitney-Test}
Der Mann-Whitney-Wilcoxon-Rangsummentest [BBH+16; CGT+14; JHHF09]
[Fie13, Seiten 541ff] wird eingesetzt, um zu entscheiden, ob sich zwei
Stichproben sich signifikant unterscheiden in dem die Werte einen Rang festgelegt wird. 
Alle Werte aus den Stichproben bekommen einen Rang aufsteigend vom Kleinsten zum Größten Wert.
Die gesamte Rangsumme lässt mit der Formel berechnen:
\begin{center}
  $T_1 + T_2 = \dfrac{n * (n + 1)}{2}, (n = n_1 + n_2)$
\end{center}  

Dabei sind $T_1$ und $T_2$ die Rangsummen aus den jeweiligen Stichproben.
Für den Test folgt ein Prüfgröße $U$  
Dieser Test
hat keine Anforderungen über die Verteilung der Stichproben.
Somit ist keine Normalverteilung der Stichproben notwendig.


\section{Konzept Analysetool}
Das Analysetool wird mit den Logs des Fio-Tools analysieren.
Das Fio-Too durchläuft 5 - 10 mal die gleichen Tests, wo dann der stationäre Zustand, des Analysetools,
bestimmt werden soll. Das Tool wird in der Lage mit den drei Tests die eingeführt zu arbeiten.
Da die Anzahl nicht festgelegt werden kann, da die dieser Zustand an einem unbestimmten Zeitpunkt und Iteration erreicht wird,
werden verschiedene Anläufe getestet mit einer verschieden Anzahl and Fio-Tool Testanzahl.

